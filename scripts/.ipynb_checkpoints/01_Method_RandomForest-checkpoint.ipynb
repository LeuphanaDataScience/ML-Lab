{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from datetime import datetime\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Google Drive\\00_Uni Leuphana\\03_3. Semester\\03_ML Lab\\ML-Lab\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "# Control panel\n",
    "scoreNormalized = False\n",
    "featureNormalized = True\n",
    "\n",
    "#%% Preprocessing\n",
    "# Load data\n",
    "X_t = pd.read_csv(\"data/X_t.csv\")\n",
    "X_tr = pd.read_csv(\"data/X_tr.csv\")\n",
    "y_t = pd.read_csv(\"data/y_t.csv\")\n",
    "y_tr = pd.read_csv(\"data/y_tr.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize popularity score\n",
    "if scoreNormalized == True:\n",
    "    \n",
    "    # Calculate mean and std for the training set\n",
    "    trainStd = np.std(y_tr[\"popularity\"])\n",
    "    trainMean = np.mean(y_tr[\"popularity\"])\n",
    "    \n",
    "    # Normalize training set and test set based on training set parameter\n",
    "    y_tr[\"popularity\"] = (y_tr[\"popularity\"]  - trainMean) / trainStd\n",
    "    y_t[\"popularity\"] = (y_t[\"popularity\"]  - trainMean) / trainStd\n",
    " \n",
    "# Normalize features   \n",
    "if featureNormalized == True: \n",
    "    #needNormalize = [\"duration_ms\", \"energy\", \"instrumentalness\", \"key\", \"loudness\", \"tempo\"]\n",
    "    \n",
    "    # Calculate mean and std for the training set\n",
    "    scaler = StandardScaler().fit(X_tr.loc[:,\"acousticness\":\"valence\"])\n",
    "    \n",
    "    # Normalize training set\n",
    "    X_tr.loc[:,\"acousticness\":\"valence\"] = scaler.transform(X_tr.loc[:,\"acousticness\":\"valence\"])\n",
    "    \n",
    "    # Normalize test set based on training set parameter\n",
    "    X_t.loc[:,\"acousticness\":\"valence\"] = scaler.transform(X_t.loc[:,\"acousticness\":\"valence\"])\n",
    "    \n",
    "# Convert column into 1D array (for training labels)\n",
    "y_tr = np.array(y_tr).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Grid search\n",
    "# Prepare grid hyperparameters\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [50, 100, 200, 500]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [20, 40, 100]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 1000\n",
      "building tree 2 of 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 3 of 1000\n",
      "building tree 4 of 1000\n",
      "building tree 5 of 1000\n",
      "building tree 6 of 1000\n",
      "building tree 7 of 1000\n",
      "building tree 8 of 1000\n",
      "building tree 9 of 1000\n",
      "building tree 10 of 1000\n",
      "building tree 11 of 1000\n",
      "building tree 12 of 1000\n",
      "building tree 13 of 1000\n",
      "building tree 14 of 1000\n",
      "building tree 15 of 1000\n",
      "building tree 16 of 1000\n",
      "building tree 17 of 1000\n",
      "building tree 18 of 1000\n",
      "building tree 19 of 1000\n",
      "building tree 20 of 1000\n",
      "building tree 21 of 1000\n",
      "building tree 22 of 1000\n",
      "building tree 23 of 1000\n",
      "building tree 24 of 1000\n",
      "building tree 25 of 1000\n",
      "building tree 26 of 1000\n",
      "building tree 27 of 1000\n",
      "building tree 28 of 1000\n",
      "building tree 29 of 1000\n",
      "building tree 30 of 1000\n",
      "building tree 31 of 1000\n",
      "building tree 32 of 1000\n",
      "building tree 33 of 1000\n",
      "building tree 34 of 1000\n",
      "building tree 35 of 1000\n",
      "building tree 36 of 1000\n",
      "building tree 37 of 1000\n",
      "building tree 38 of 1000\n",
      "building tree 39 of 1000\n"
     ]
    }
   ],
   "source": [
    "#%% Run base model\n",
    "RFBase = RandomForestRegressor(n_estimators = 1000, max_features = \"sqrt\", bootstrap = True, random_state = 2312, verbose = 3, max_samples =   0.3)\n",
    "\n",
    "# Cross validation\n",
    "RFCV = cross_val_score(RFBase, X_tr, y_tr, scoring=('neg_mean_squared_error'))\n",
    "RFR2 = cross_val_score(RFBase, X_tr, y_tr, scoring=('r2'))\n",
    "\n",
    "print(\"R2\")\n",
    "np.mean(RFR2)\n",
    "np.std(RFR2)\n",
    "\n",
    "print(\"RMSE\")\n",
    "np.mean(RFCV)\n",
    "np.std(RFCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
